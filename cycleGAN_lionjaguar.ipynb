{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycleGAN_lionjaguar.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNK88ZtI58HrhAzvTr9mYqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mondardo/cycleGAN/blob/main/cycleGAN_lionjaguar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BwB-WHQ4S9t",
        "outputId": "79975c11-4edc-47b0-944a-e085d09bcd38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out NVIDIA GPU model (randomly assigned by Colab)\n",
        "gpu = !nvidia-smi -L\n",
        "print('Not using GPU' if 'failed' in gpu[0] else gpu[0].split(' (')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeRR9VRS4gn1",
        "outputId": "7ca8400b-0815-4c54-f006-631216bddfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy.random import shuffle\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "BMw-QQNb4kjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frechet Inception Distance (FID):"
      ],
      "metadata": {
        "id": "0ECEiqO9q0n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn np.asarray(images_list)\n",
        " \n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, test_images):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(test_images)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif np.iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid\n",
        " \n",
        "# prepare the inception v3 model\n",
        "model_inceptionV3 = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
      ],
      "metadata": {
        "id": "RBCTNzwX4nrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425fcaa1-b5cd-42c6-f016-2391bd9345b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1350\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "\n",
        "def random_crop(image):\n",
        "  cropped_image = tf.image.random_crop(\n",
        "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "  return cropped_image\n",
        "\n",
        "# normalizing the images to [-1, 1]\n",
        "def normalize(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image / 127.5) - 1\n",
        "  return image\n",
        "\n",
        "def random_jitter(image):\n",
        "  # resizing to 286 x 286 x 3\n",
        "  image = tf.image.resize(image, [286, 286],\n",
        "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "  image = random_crop(image)\n",
        "\n",
        "  # random mirroring\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "  return image\n",
        "\n",
        "def preprocess_image_train(image):\n",
        "  image = random_jitter(image)\n",
        "  image = normalize(image)\n",
        "  return image\n",
        "\n",
        "def preprocess_image_test(image):\n",
        "  image = normalize(image)\n",
        "  return image"
      ],
      "metadata": {
        "id": "LKX-nCRi4n7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess lion images:"
      ],
      "metadata": {
        "id": "KRcqRx1Hq_BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/Colab Notebooks/lion/'\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "train_images = []\n",
        "\n",
        "images = os.listdir(path)[0:BUFFER_SIZE]\n",
        "\n",
        "for i in images: # all train cat images\n",
        "    if os.path.isfile(path + i): # check image in file\n",
        "        image = Image.open(path + i)\n",
        "        image = image.resize((img_size,img_size), Image.ANTIALIAS) # resizing\n",
        "        image = np.asarray(image) # bit format\n",
        "        if (image.ndim == 3) and (image.shape[2] == 3):\n",
        "          train_images.append(image)\n",
        "\n",
        "np.shape(train_images)\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "train_images = train_images.astype('float32')"
      ],
      "metadata": {
        "id": "LC8iM8qI44Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lion, test_lion = train_test_split(train_images, test_size=0.1)\n",
        "print(f'Lions Train set shape: {train_lion.shape}')\n",
        "print(f'Lions Test set shape:  {test_lion.shape}')"
      ],
      "metadata": {
        "id": "g9YMZX59rGHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lion = tf.data.Dataset.from_tensor_slices(train_lion).prefetch(1)\n",
        "train_lion = train_lion.cache().map(preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "test_lion = tf.data.Dataset.from_tensor_slices(test_lion).prefetch(1)\n",
        "test_lion = test_lion.cache().map(preprocess_image_test, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "hvOifEBx5XBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_lion = np.zeros(len(test_lion)*256*256*3).reshape(len(test_lion),256,256,3)\n",
        "\n",
        "n = 0\n",
        "for i in iter(test_lion):\n",
        "  sample_lion[n,:,:,:] = i\n",
        "  n = n + 1"
      ],
      "metadata": {
        "id": "k6FH6mYL7GNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess jaguar images:"
      ],
      "metadata": {
        "id": "h9jbyTtIrMuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/Colab Notebooks/jaguar/'\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "train_images = []\n",
        "\n",
        "images = os.listdir(path)[0:BUFFER_SIZE]\n",
        "\n",
        "for i in images: # all train cat images\n",
        "    if os.path.isfile(path + i): # check image in file\n",
        "        image = Image.open(path + i)\n",
        "        image = image.resize((img_size,img_size), Image.ANTIALIAS) # resizing\n",
        "        image = np.asarray(image) # bit format\n",
        "        # print(type(image))\n",
        "        if (image.ndim == 3) and (image.shape[2] == 3):\n",
        "          train_images.append(image)\n",
        "\n",
        "np.shape(train_images)\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "train_images = train_images.astype('float32')"
      ],
      "metadata": {
        "id": "SpIJCweC7QYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_jaguar, test_jaguar = train_test_split(train_images, test_size=0.1)\n",
        "print(f'Jaguar Train set shape: {train_jaguar.shape}')\n",
        "print(f'Jaguar Test set shape:  {test_jaguar.shape}')"
      ],
      "metadata": {
        "id": "jz0p4LvyraNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tiger = tf.data.Dataset.from_tensor_slices(train_tiger).prefetch(1)\n",
        "train_tiger = train_tiger.cache().map(preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "test_tiger = tf.data.Dataset.from_tensor_slices(test_tiger).prefetch(1)\n",
        "test_tiger = test_tiger.cache().map(preprocess_image_test, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "oyqN-VS7-8O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tiger = np.zeros(len(test_tiger)*256*256*3).reshape(len(test_tiger),256,256,3)\n",
        "\n",
        "n = 0\n",
        "for i in iter(test_tiger):\n",
        "  sample_tiger[n,:,:,:] = i\n",
        "  n = n + 1"
      ],
      "metadata": {
        "id": "xysIas8CDA0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instance normalization:"
      ],
      "metadata": {
        "id": "ZTz1czKGrdKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "  \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n",
        "\n",
        "  def __init__(self, epsilon=1e-5):\n",
        "    super(InstanceNormalization, self).__init__()\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.scale = self.add_weight(\n",
        "        name='scale',\n",
        "        shape=input_shape[-1:],\n",
        "        initializer=tf.random_normal_initializer(1., 0.02),\n",
        "        trainable=True)\n",
        "\n",
        "    self.offset = self.add_weight(\n",
        "        name='offset',\n",
        "        shape=input_shape[-1:],\n",
        "        initializer='zeros',\n",
        "        trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "    inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "    normalized = (x - mean) * inv\n",
        "    return self.scale * normalized + self.offset"
      ],
      "metadata": {
        "id": "ktbShpScDLgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downsample layers:"
      ],
      "metadata": {
        "id": "JBTvCLcfrf7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample(filters, size, apply_norm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_norm:\n",
        "    result.add(InstanceNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "FQ60w5oJDg62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsample layers:"
      ],
      "metadata": {
        "id": "T0Mqg9UiriSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=False))\n",
        "\n",
        "  result.add(InstanceNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "    result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "l5C312X_DiiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator net:"
      ],
      "metadata": {
        "id": "yIyJt5ycrmpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_generator(output_channels):\n",
        "  \"\"\"Modified u-net generator model (https://arxiv.org/abs/1611.07004)\"\"\"\n",
        "\n",
        "  down_stack = [\n",
        "      downsample(64, 4, apply_norm=False),  # (bs, 128, 128, 64)\n",
        "      downsample(128, 4),  # (bs, 64, 64, 128)\n",
        "      downsample(256, 4),  # (bs, 32, 32, 256)\n",
        "      downsample(512, 4),  # (bs, 16, 16, 512)\n",
        "      downsample(512, 4),  # (bs, 8, 8, 512)\n",
        "      downsample(512, 4),  # (bs, 4, 4, 512)\n",
        "      downsample(512, 4),  # (bs, 2, 2, 512)\n",
        "      downsample(512, 4),  # (bs, 1, 1, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "      upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
        "      upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
        "      upsample(512, 4),  # (bs, 16, 16, 1024)\n",
        "      upsample(256, 4),  # (bs, 32, 32, 512)\n",
        "      upsample(128, 4),  # (bs, 64, 64, 256)\n",
        "      upsample(64, 4),  # (bs, 128, 128, 128)\n",
        "  ]\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 4, strides=2,\n",
        "      padding='same', kernel_initializer=initializer,\n",
        "      activation='tanh')  # (bs, 256, 256, 3)\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[None, None, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "dt8Aoh7WDj1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator net:"
      ],
      "metadata": {
        "id": "yHdUx3WXrqkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(target=True):\n",
        "  \"\"\"PatchGan discriminator model (https://arxiv.org/abs/1611.07004).\"\"\"\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[None, None, 3], name='input_image')\n",
        "  x = inp\n",
        "\n",
        "  if target:\n",
        "    tar = tf.keras.layers.Input(shape=[None, None, 3], name='target_image')\n",
        "    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1)  # (bs, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(\n",
        "      512, 4, strides=1, kernel_initializer=initializer,\n",
        "      use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n",
        "\n",
        "  norm1 = InstanceNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(\n",
        "      1, 4, strides=1,\n",
        "      kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n",
        "\n",
        "  if target:\n",
        "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
        "  else:\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)"
      ],
      "metadata": {
        "id": "pBsg8l89Dlj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "\n",
        "generator_g = unet_generator(OUTPUT_CHANNELS)\n",
        "generator_f = unet_generator(OUTPUT_CHANNELS)\n",
        "\n",
        "discriminator_x = discriminator(target=False)\n",
        "discriminator_y = discriminator(target=False)"
      ],
      "metadata": {
        "id": "-q2z1lZdDnVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cycle loss and identity loss hyperparameter:\n",
        "LAMBDA = 10"
      ],
      "metadata": {
        "id": "oFWAE3vPEody"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "zA4W3KIxE0Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real, generated):\n",
        "  # real: output do discriminador quando recebe uma imagem real\n",
        "  # generated: output do discriminador quando recebe uma imagem gerada pelo gerador (imagem fake)\n",
        "  real_loss = loss_obj(tf.ones_like(real), real)\n",
        "\n",
        "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss * 0.5\n",
        "\n",
        "def generator_loss(generated):\n",
        "  return loss_obj(tf.ones_like(generated), generated)\n",
        "\n",
        "def calc_cycle_loss(real_image, cycled_image):\n",
        "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image)) # reduce_mean eh o mean simplesmente tipo np.mean\n",
        "  \n",
        "  return LAMBDA * loss1\n",
        "\n",
        "def identity_loss(real_image, same_image):\n",
        "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "  return LAMBDA * 0.5 * loss"
      ],
      "metadata": {
        "id": "40H3wa9yE1ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_g_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "generator_f_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "discriminator_x_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "hvJaWL6BE2JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/gdrive/My Drive/Colab Notebooks/lionjaguar_checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           generator_f=generator_f,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           discriminator_y=discriminator_y,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           generator_f_optimizer=generator_f_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
        "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "id": "VAZ5mP9KE_9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 90"
      ],
      "metadata": {
        "id": "ghHzwobjFNao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, test_input, input_horses_test, images2, fids, epoch):\n",
        "  for j in range(test_input.shape[0]):\n",
        "    prediction = model(test_input[j:j+1,:,:,:])\n",
        "    \n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    display_list = [test_input[j], prediction[0]]\n",
        "    title = ['Input Image', 'Predicted Image']\n",
        "\n",
        "    for i in range(2):\n",
        "      plt.subplot(1, 2, i+1)\n",
        "      plt.title(title[i])\n",
        "      # getting the pixel values between [0, 1] to plot it.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "    plt.savefig('/content/gdrive/My Drive/Colab Notebooks/lionjaguar/image_{:04d}_at_epoch_{:04d}.png'.format(j+1, epoch+1))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "  images1 = model(input_horses_test).numpy()\n",
        "  shuffle(images1)\n",
        "  ## convert integer to floating point values\n",
        "  images1 = images1.astype('float32')\n",
        "  images2 = images2.astype('float32')\n",
        "  # resize images\n",
        "  images1 = scale_images(images1, (299,299,3))\n",
        "  images2 = scale_images(images2, (299,299,3))\n",
        "  ## pre-process images\n",
        "  images1 = preprocess_input(images1)\n",
        "  images2 = preprocess_input(images2)\n",
        "  # calculate fid\n",
        "  # if (epoch + 5) % 5 == 0:\n",
        "  fid = calculate_fid(model_inceptionV3, images1, images2)\n",
        "  fids.append(fid)\n",
        "  return fids"
      ],
      "metadata": {
        "id": "IpIPmcbXFO5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "  # persistent is set to True because the tape is used more than\n",
        "  # once to calculate the gradients.\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Generator G translates X -> Y\n",
        "    # Generator F translates Y -> X.\n",
        "    \n",
        "    fake_y = generator_g(real_x, training=True)\n",
        "    cycled_x = generator_f(fake_y, training=True)\n",
        "\n",
        "    fake_x = generator_f(real_y, training=True)\n",
        "    cycled_y = generator_g(fake_x, training=True)\n",
        "\n",
        "    # same_x and same_y are used for identity loss.\n",
        "    same_x = generator_f(real_x, training=True)\n",
        "    same_y = generator_g(real_y, training=True)\n",
        "\n",
        "    disc_real_x = discriminator_x(real_x, training=True)\n",
        "    disc_real_y = discriminator_y(real_y, training=True)\n",
        "\n",
        "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
        "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
        "\n",
        "    # calculate the loss\n",
        "    gen_g_loss = generator_loss(disc_fake_y)\n",
        "    gen_f_loss = generator_loss(disc_fake_x)\n",
        "    \n",
        "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        "    \n",
        "    # Total generator loss = adversarial loss + cycle loss\n",
        "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
        "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "  \n",
        "  # Calculate the gradients for generator and discriminator\n",
        "  generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
        "                                        generator_g.trainable_variables)\n",
        "  generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
        "                                        generator_f.trainable_variables)\n",
        "  \n",
        "  discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
        "                                            discriminator_x.trainable_variables)\n",
        "  discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
        "                                            discriminator_y.trainable_variables)\n",
        "  \n",
        "  # Apply the gradients to the optimizer\n",
        "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
        "                                            generator_g.trainable_variables))\n",
        "\n",
        "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
        "                                            generator_f.trainable_variables))\n",
        "  \n",
        "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
        "                                                discriminator_x.trainable_variables))\n",
        "  \n",
        "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
        "                                                discriminator_y.trainable_variables))\n",
        "  return total_gen_g_loss, total_gen_f_loss, disc_x_loss, disc_y_loss"
      ],
      "metadata": {
        "id": "7PZypqilFTqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_gen_g_losses = []\n",
        "total_gen_f_losses = []\n",
        "disc_x_losses = []\n",
        "disc_y_losses = []\n",
        "fids = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  n = 0\n",
        "  for image_x, image_y in tf.data.Dataset.zip((train_lion, train_tiger)):\n",
        "    total_gen_g_loss, total_gen_f_loss, disc_x_loss, disc_y_loss = train_step(image_x, image_y)\n",
        "    total_gen_g_losses.append(total_gen_g_loss)\n",
        "    total_gen_f_losses.append(total_gen_f_loss)\n",
        "    disc_x_losses.append(disc_x_loss)\n",
        "    disc_y_losses.append(disc_y_loss)\n",
        "\n",
        "    if n % 10 == 0:\n",
        "      print ('.', end='')\n",
        "    n += 1\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  # Using a consistent image (sample_horse) so that the progress of the model\n",
        "  # is clearly visible.\n",
        "  fids = generate_images(generator_g, sample_lion[20:30,:,:,:], sample_lion, sample_tiger, fids, epoch)\n",
        "\n",
        "  if (epoch + 1) % 20 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "\n",
        "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                      time.time()-start))\n",
        "  \n",
        "  total_gen_g_losses_new = []\n",
        "  for i in total_gen_g_losses:\n",
        "    total_gen_g_losses_new.append(i.numpy())\n",
        "\n",
        "  total_gen_f_losses_new = []\n",
        "  for i in total_gen_f_losses:\n",
        "    total_gen_f_losses_new.append(i.numpy())\n",
        "    \n",
        "  disc_x_losses_new = []\n",
        "  for i in disc_x_losses:\n",
        "    disc_x_losses_new.append(i.numpy())\n",
        "\n",
        "  disc_y_losses_new = []\n",
        "  for i in disc_y_losses:\n",
        "    disc_y_losses_new.append(i.numpy())\n",
        "\n",
        "  np.savetxt(\"/content/gdrive/My Drive/Colab Notebooks/lionjaguar/gen_g_losses.csv\", total_gen_g_losses_new)\n",
        "  np.savetxt(\"/content/gdrive/My Drive/Colab Notebooks/lionjaguar/gen_f_losses.csv\", total_gen_f_losses_new)\n",
        "  np.savetxt(\"/content/gdrive/My Drive/Colab Notebooks/lionjaguar/disc_x_losses.csv\", disc_x_losses_new)\n",
        "  np.savetxt(\"/content/gdrive/My Drive/Colab Notebooks/lionjaguar/disc_y_losses.csv\", disc_y_losses_new)\n",
        "  np.savetxt(\"/content/gdrive/My Drive/Colab Notebooks/lionjaguar/fids.csv\", fids)\n",
        "  \n"
      ],
      "metadata": {
        "id": "19ipliZrFWJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_save_path = ckpt_manager.save()"
      ],
      "metadata": {
        "id": "XzXG2c34Kmci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8erBmpd1HXjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}